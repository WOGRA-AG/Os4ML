apiVersion: argoproj.io/v1alpha1
kind: Workflow
metadata:
  annotations:
    pipelines.kubeflow.org/kfp_sdk_version: 1.8.12
    pipelines.kubeflow.org/pipeline_compilation_time: '2022-06-27T15:14:36.587130'
    pipelines.kubeflow.org/pipeline_spec: '{"inputs": [{"default": "os4ml", "name":
      "bucket", "optional": true, "type": "String"}, {"default": "titanic.xlsx", "name":
      "file_name", "optional": true, "type": "String"}, {"default": "", "name": "solution_name",
      "optional": true, "type": "String"}, {"default": "", "name": "pipeline-root"},
      {"default": "pipeline/titanic-randomforest-pipeline", "name": "pipeline-name"}],
      "name": "titanic-randomforest-pipeline"}'
    pipelines.kubeflow.org/v2_pipeline: 'true'
  generateName: titanic-randomforest-pipeline-
  labels:
    pipelines.kubeflow.org/kfp_sdk_version: 1.8.12
    pipelines.kubeflow.org/v2_pipeline: 'true'
spec:
  arguments:
    parameters:
    - name: bucket
      value: os4ml
    - name: file_name
      value: titanic.xlsx
    - name: solution_name
      value: ''
    - name: pipeline-root
      value: ''
    - name: pipeline-name
      value: pipeline/titanic-randomforest-pipeline
  entrypoint: titanic-randomforest-pipeline
  imagePullSecrets:
  - name: registry-credentials
  serviceAccountName: pipeline-runner
  templates:
  - container:
      args:
      - sh
      - -c
      - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3\
        \ -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
        \ python3 -m pip install --quiet     --no-warn-script-location 'kfp==1.8.12'\
        \ && \"$0\" \"$@\"\n"
      - sh
      - -ec
      - 'program_path=$(mktemp -d)

        printf "%s" "$0" > "$program_path/ephemeral_component.py"

        python3 -m kfp.v2.components.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

        '
      - "\nimport kfp\nfrom kfp.v2 import dsl\nfrom kfp.v2.dsl import *\nfrom typing\
        \ import *\n\ndef get_metrics(metrics: Input[Metrics], solution_name: str\
        \ = \"\"):\n    from src.components.get_metrics import get_metrics\n\n   \
        \ return get_metrics(metrics, solution_name=solution_name)\n\n"
      - --executor_input
      - '{{$}}'
      - --function_to_execute
      - get_metrics
      command:
      - /kfp-launcher/launch
      - --mlmd_server_address
      - $(METADATA_GRPC_SERVICE_HOST)
      - --mlmd_server_port
      - $(METADATA_GRPC_SERVICE_PORT)
      - --runtime_info_json
      - $(KFP_V2_RUNTIME_INFO)
      - --container_image
      - $(KFP_V2_IMAGE)
      - --task_name
      - get-metrics
      - --pipeline_name
      - '{{inputs.parameters.pipeline-name}}'
      - --run_id
      - $(KFP_RUN_ID)
      - --run_resource
      - workflows.argoproj.io/$(WORKFLOW_ID)
      - --namespace
      - $(KFP_NAMESPACE)
      - --pod_name
      - $(KFP_POD_NAME)
      - --pod_uid
      - $(KFP_POD_UID)
      - --pipeline_root
      - '{{inputs.parameters.pipeline-root}}'
      - --enable_caching
      - $(ENABLE_CACHING)
      - --
      - solution_name={{inputs.parameters.solution_name}}
      - --
      env:
      - name: KFP_POD_NAME
        valueFrom:
          fieldRef:
            fieldPath: metadata.name
      - name: KFP_POD_UID
        valueFrom:
          fieldRef:
            fieldPath: metadata.uid
      - name: KFP_NAMESPACE
        valueFrom:
          fieldRef:
            fieldPath: metadata.namespace
      - name: WORKFLOW_ID
        valueFrom:
          fieldRef:
            fieldPath: metadata.labels['workflows.argoproj.io/workflow']
      - name: KFP_RUN_ID
        valueFrom:
          fieldRef:
            fieldPath: metadata.labels['pipeline/runid']
      - name: ENABLE_CACHING
        valueFrom:
          fieldRef:
            fieldPath: metadata.labels['pipelines.kubeflow.org/enable_caching']
      - name: KFP_V2_IMAGE
        value: gitlab-registry.wogra.com/developer/wogra/os4ml/python:latest
      - name: KFP_V2_RUNTIME_INFO
        value: '{"inputParameters": {"solution_name": {"type": "STRING"}}, "inputArtifacts":
          {"metrics": {"metadataPath": "/tmp/inputs/metrics/data", "schemaTitle":
          "system.Metrics", "instanceSchema": "", "schemaVersion": "0.0.1"}}, "outputParameters":
          {}, "outputArtifacts": {}}'
      envFrom:
      - configMapRef:
          name: metadata-grpc-configmap
          optional: true
      - configMapRef:
          name: os4ml-pipeline
          optional: true
      image: gitlab-registry.wogra.com/developer/wogra/os4ml/python:latest
      volumeMounts:
      - mountPath: /kfp-launcher
        name: kfp-launcher
    initContainers:
    - command:
      - launcher
      - --copy
      - /kfp-launcher/launch
      image: gcr.io/ml-pipeline/kfp-launcher:1.8.7
      mirrorVolumeMounts: true
      name: kfp-launcher
    inputs:
      artifacts:
      - name: train-random-forest-metrics
        path: /tmp/inputs/metrics/data
      parameters:
      - name: pipeline-name
      - name: pipeline-root
      - name: solution_name
    metadata:
      annotations:
        pipelines.kubeflow.org/arguments.parameters: '{"solution_name": "{{inputs.parameters.solution_name}}"}'
        pipelines.kubeflow.org/component_ref: '{"digest": "a5173deef9d23be315e89d045fa7f194d528e54a688835f7497de7192438f709",
          "url": "../../components/get-metrics/component.yaml"}'
        pipelines.kubeflow.org/v2_component: 'true'
      labels:
        pipelines.kubeflow.org/enable_caching: 'true'
        pipelines.kubeflow.org/kfp_sdk_version: 1.8.12
        pipelines.kubeflow.org/pipeline-sdk-type: kfp
        pipelines.kubeflow.org/v2_component: 'true'
    name: get-metrics
    volumes:
    - name: kfp-launcher
  - container:
      args:
      - sh
      - -c
      - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3\
        \ -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
        \ python3 -m pip install --quiet     --no-warn-script-location 'kfp==1.8.12'\
        \ && \"$0\" \"$@\"\n"
      - sh
      - -ec
      - 'program_path=$(mktemp -d)

        printf "%s" "$0" > "$program_path/ephemeral_component.py"

        python3 -m kfp.v2.components.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

        '
      - "\nimport kfp\nfrom kfp.v2 import dsl\nfrom kfp.v2.dsl import *\nfrom typing\
        \ import *\n\ndef init_databag(\n    file_name: str, bucket: str, solution_name:\
        \ str = \"\"\n) -> NamedTuple(\"DatabagInfo\", [(\"databag_type\", str), (\"\
        dataset\", Dataset)]):\n    from src.components.init_databag import init_databag\n\
        \n    return init_databag(file_name, bucket=bucket, solution_name=solution_name)\n\
        \n"
      - --executor_input
      - '{{$}}'
      - --function_to_execute
      - init_databag
      command:
      - /kfp-launcher/launch
      - --mlmd_server_address
      - $(METADATA_GRPC_SERVICE_HOST)
      - --mlmd_server_port
      - $(METADATA_GRPC_SERVICE_PORT)
      - --runtime_info_json
      - $(KFP_V2_RUNTIME_INFO)
      - --container_image
      - $(KFP_V2_IMAGE)
      - --task_name
      - init-databag
      - --pipeline_name
      - '{{inputs.parameters.pipeline-name}}'
      - --run_id
      - $(KFP_RUN_ID)
      - --run_resource
      - workflows.argoproj.io/$(WORKFLOW_ID)
      - --namespace
      - $(KFP_NAMESPACE)
      - --pod_name
      - $(KFP_POD_NAME)
      - --pod_uid
      - $(KFP_POD_UID)
      - --pipeline_root
      - '{{inputs.parameters.pipeline-root}}'
      - --enable_caching
      - $(ENABLE_CACHING)
      - --
      - bucket={{inputs.parameters.file_name}}
      - file_name={{inputs.parameters.bucket}}
      - solution_name=
      - --
      env:
      - name: KFP_POD_NAME
        valueFrom:
          fieldRef:
            fieldPath: metadata.name
      - name: KFP_POD_UID
        valueFrom:
          fieldRef:
            fieldPath: metadata.uid
      - name: KFP_NAMESPACE
        valueFrom:
          fieldRef:
            fieldPath: metadata.namespace
      - name: WORKFLOW_ID
        valueFrom:
          fieldRef:
            fieldPath: metadata.labels['workflows.argoproj.io/workflow']
      - name: KFP_RUN_ID
        valueFrom:
          fieldRef:
            fieldPath: metadata.labels['pipeline/runid']
      - name: ENABLE_CACHING
        valueFrom:
          fieldRef:
            fieldPath: metadata.labels['pipelines.kubeflow.org/enable_caching']
      - name: KFP_V2_IMAGE
        value: gitlab-registry.wogra.com/developer/wogra/os4ml/pandas:latest
      - name: KFP_V2_RUNTIME_INFO
        value: '{"inputParameters": {"bucket": {"type": "STRING"}, "file_name": {"type":
          "STRING"}, "solution_name": {"type": "STRING"}}, "inputArtifacts": {}, "outputParameters":
          {"databag_type": {"type": "STRING", "path": "/tmp/outputs/databag_type/data"}},
          "outputArtifacts": {"dataset": {"schemaTitle": "system.Dataset", "instanceSchema":
          "", "schemaVersion": "0.0.1", "metadataPath": "/tmp/outputs/dataset/data"}}}'
      envFrom:
      - configMapRef:
          name: metadata-grpc-configmap
          optional: true
      - configMapRef:
          name: os4ml-pipeline
          optional: true
      image: gitlab-registry.wogra.com/developer/wogra/os4ml/pandas:latest
      volumeMounts:
      - mountPath: /kfp-launcher
        name: kfp-launcher
    initContainers:
    - command:
      - launcher
      - --copy
      - /kfp-launcher/launch
      image: gcr.io/ml-pipeline/kfp-launcher:1.8.7
      mirrorVolumeMounts: true
      name: kfp-launcher
    inputs:
      parameters:
      - name: bucket
      - name: file_name
      - name: pipeline-name
      - name: pipeline-root
    metadata:
      annotations:
        pipelines.kubeflow.org/arguments.parameters: '{"bucket": "{{inputs.parameters.file_name}}",
          "file_name": "{{inputs.parameters.bucket}}", "solution_name": ""}'
        pipelines.kubeflow.org/component_ref: '{"digest": "2678eef377710fcbd0b47d78e64f0d1cb25150d409f3de1be59b3fdf545efa01",
          "url": "../../components/init-databag/component.yaml"}'
        pipelines.kubeflow.org/v2_component: 'true'
      labels:
        pipelines.kubeflow.org/enable_caching: 'true'
        pipelines.kubeflow.org/kfp_sdk_version: 1.8.12
        pipelines.kubeflow.org/pipeline-sdk-type: kfp
        pipelines.kubeflow.org/v2_component: 'true'
    name: init-databag
    outputs:
      artifacts:
      - name: init-databag-databag_type
        path: /tmp/outputs/databag_type/data
      - name: init-databag-dataset
        path: /tmp/outputs/dataset/data
    volumes:
    - name: kfp-launcher
  - container:
      args:
      - sh
      - -c
      - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3\
        \ -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
        \ python3 -m pip install --quiet     --no-warn-script-location 'pandas>=1.4.0'\
        \ 'kfp==1.8.12' && \"$0\" \"$@\"\n"
      - sh
      - -ec
      - 'program_path=$(mktemp -d)

        printf "%s" "$0" > "$program_path/ephemeral_component.py"

        python3 -m kfp.v2.components.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

        '
      - "\nimport kfp\nfrom kfp.v2 import dsl\nfrom kfp.v2.dsl import *\nfrom typing\
        \ import *\n\ndef preprocess_data(\n    dataframe: Input[Dataset],\n) -> NamedTuple(\"\
        Data\", [(\"x\", Dataset), (\"y\", Dataset)]):\n    import re\n    from collections\
        \ import namedtuple\n\n    import numpy as np\n    import pandas as pd\n\n\
        \    with open(dataframe.path, \"r\") as f:\n        df = pd.read_csv(f)\n\
        \n    # example code from https://towardsdatascience.com/predicting-the-survival-of-titanic-passengers-30870ccc7e8\n\
        \    df = df.drop([\"PassengerId\"], axis=1)\n    deck = {\"A\": 1, \"B\"\
        : 2, \"C\": 3, \"D\": 4, \"E\": 5, \"F\": 6, \"G\": 7, \"U\": 8}\n    df[\"\
        Cabin\"] = df[\"Cabin\"].fillna(\"U0\")\n    df[\"Deck\"] = df[\"Cabin\"].map(\n\
        \        lambda x: re.compile(\"([a-zA-Z]+)\").search(x).group()\n    )\n\
        \    df[\"Deck\"] = df[\"Deck\"].map(deck).fillna(0).astype(int)\n    df =\
        \ df.drop([\"Cabin\"], axis=1)\n\n    mean = df[\"Age\"].mean()\n    std =\
        \ df[\"Age\"].std()\n    is_null = df[\"Age\"].isnull().sum()\n    # compute\
        \ random numbers between the mean, std and is_null\n    rand_age = np.random.randint(mean\
        \ - std, mean + std, size=is_null)\n    age_slice = df[\"Age\"].copy()\n \
        \   age_slice[np.isnan(age_slice)] = rand_age\n    df[\"Age\"] = age_slice.astype(int)\n\
        \n    common_value = \"S\"\n    df[\"Embarked\"] = df[\"Embarked\"].fillna(common_value)\n\
        \n    df[\"Fare\"] = df[\"Fare\"].fillna(0).astype(int)\n\n    titles = {\"\
        Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\n\n    # extract\
        \ titles\n    df[\"Title\"] = df.Name.str.extract(\" ([A-Za-z]+)\\.\", expand=False)\n\
        \    # replace titles with a more common title or as Rare\n    df[\"Title\"\
        ] = df[\"Title\"].replace(\n        [\n            \"Lady\",\n           \
        \ \"Countess\",\n            \"Capt\",\n            \"Col\",\n           \
        \ \"Don\",\n            \"Dr\",\n            \"Major\",\n            \"Rev\"\
        ,\n            \"Sir\",\n            \"Jonkheer\",\n            \"Dona\",\n\
        \        ],\n        \"Rare\",\n    )\n    df[\"Title\"] = df[\"Title\"].replace(\"\
        Mlle\", \"Miss\")\n    df[\"Title\"] = df[\"Title\"].replace(\"Ms\", \"Miss\"\
        )\n    df[\"Title\"] = df[\"Title\"].replace(\"Mme\", \"Mrs\")\n    # convert\
        \ titles into numbers\n    df[\"Title\"] = df[\"Title\"].map(titles)\n   \
        \ # filling NaN with 0, to get safe\n    df[\"Title\"] = df[\"Title\"].fillna(0)\n\
        \n    df = df.drop([\"Name\"], axis=1)\n\n    genders = {\"male\": 0, \"female\"\
        : 1}\n    df[\"Sex\"] = df[\"Sex\"].map(genders)\n\n    df = df.drop([\"Ticket\"\
        ], axis=1)\n\n    ports = {\"S\": 0, \"C\": 1, \"Q\": 2}\n    df[\"Embarked\"\
        ] = df[\"Embarked\"].map(ports)\n\n    df[\"relatives\"] = df[\"SibSp\"] +\
        \ df[\"Parch\"]\n\n    # Create Categories\n    df[\"Age\"] = df[\"Age\"].astype(int)\n\
        \    df.loc[df[\"Age\"] <= 11, \"Age\"] = 0\n    df.loc[(df[\"Age\"] > 11)\
        \ & (df[\"Age\"] <= 18), \"Age\"] = 1\n    df.loc[(df[\"Age\"] > 18) & (df[\"\
        Age\"] <= 22), \"Age\"] = 2\n    df.loc[(df[\"Age\"] > 22) & (df[\"Age\"]\
        \ <= 27), \"Age\"] = 3\n    df.loc[(df[\"Age\"] > 27) & (df[\"Age\"] <= 33),\
        \ \"Age\"] = 4\n    df.loc[(df[\"Age\"] > 33) & (df[\"Age\"] <= 40), \"Age\"\
        ] = 5\n    df.loc[(df[\"Age\"] > 40) & (df[\"Age\"] <= 66), \"Age\"] = 6\n\
        \    df.loc[df[\"Age\"] > 66, \"Age\"] = 6\n\n    # Fare\n    df.loc[df[\"\
        Fare\"] <= 7.91, \"Fare\"] = 0\n    df.loc[(df[\"Fare\"] > 7.91) & (df[\"\
        Fare\"] <= 14.454), \"Fare\"] = 1\n    df.loc[(df[\"Fare\"] > 14.454) & (df[\"\
        Fare\"] <= 31), \"Fare\"] = 2\n    df.loc[(df[\"Fare\"] > 31) & (df[\"Fare\"\
        ] <= 99), \"Fare\"] = 3\n    df.loc[(df[\"Fare\"] > 99) & (df[\"Fare\"] <=\
        \ 250), \"Fare\"] = 4\n    df.loc[df[\"Fare\"] > 250, \"Fare\"] = 5\n    df[\"\
        Fare\"] = df[\"Fare\"].astype(int)\n\n    df[\"Age_Class\"] = df[\"Age\"]\
        \ * df[\"Pclass\"]\n\n    df[\"Fare_Per_Person\"] = df[\"Fare\"] / (df[\"\
        relatives\"] + 1)\n    df[\"Fare_Per_Person\"] = df[\"Fare_Per_Person\"].astype(int)\n\
        \n    df_x = df.drop([\"Survived\"], axis=1)\n    df_y = df[\"Survived\"]\n\
        \n    output = namedtuple(\"Data\", [\"x\", \"y\"])\n    return output(df_x.to_csv(index=False),\
        \ df_y.to_csv(index=False))\n\n"
      - --executor_input
      - '{{$}}'
      - --function_to_execute
      - preprocess_data
      command:
      - /kfp-launcher/launch
      - --mlmd_server_address
      - $(METADATA_GRPC_SERVICE_HOST)
      - --mlmd_server_port
      - $(METADATA_GRPC_SERVICE_PORT)
      - --runtime_info_json
      - $(KFP_V2_RUNTIME_INFO)
      - --container_image
      - $(KFP_V2_IMAGE)
      - --task_name
      - preprocess-data
      - --pipeline_name
      - '{{inputs.parameters.pipeline-name}}'
      - --run_id
      - $(KFP_RUN_ID)
      - --run_resource
      - workflows.argoproj.io/$(WORKFLOW_ID)
      - --namespace
      - $(KFP_NAMESPACE)
      - --pod_name
      - $(KFP_POD_NAME)
      - --pod_uid
      - $(KFP_POD_UID)
      - --pipeline_root
      - '{{inputs.parameters.pipeline-root}}'
      - --enable_caching
      - $(ENABLE_CACHING)
      - --
      - --
      env:
      - name: KFP_POD_NAME
        valueFrom:
          fieldRef:
            fieldPath: metadata.name
      - name: KFP_POD_UID
        valueFrom:
          fieldRef:
            fieldPath: metadata.uid
      - name: KFP_NAMESPACE
        valueFrom:
          fieldRef:
            fieldPath: metadata.namespace
      - name: WORKFLOW_ID
        valueFrom:
          fieldRef:
            fieldPath: metadata.labels['workflows.argoproj.io/workflow']
      - name: KFP_RUN_ID
        valueFrom:
          fieldRef:
            fieldPath: metadata.labels['pipeline/runid']
      - name: ENABLE_CACHING
        valueFrom:
          fieldRef:
            fieldPath: metadata.labels['pipelines.kubeflow.org/enable_caching']
      - name: KFP_V2_IMAGE
        value: python:3.9.10-slim
      - name: KFP_V2_RUNTIME_INFO
        value: '{"inputParameters": {}, "inputArtifacts": {"dataframe": {"metadataPath":
          "/tmp/inputs/dataframe/data", "schemaTitle": "system.Dataset", "instanceSchema":
          "", "schemaVersion": "0.0.1"}}, "outputParameters": {}, "outputArtifacts":
          {"x": {"schemaTitle": "system.Dataset", "instanceSchema": "", "schemaVersion":
          "0.0.1", "metadataPath": "/tmp/outputs/x/data"}, "y": {"schemaTitle": "system.Dataset",
          "instanceSchema": "", "schemaVersion": "0.0.1", "metadataPath": "/tmp/outputs/y/data"}}}'
      envFrom:
      - configMapRef:
          name: metadata-grpc-configmap
          optional: true
      - configMapRef:
          name: os4ml-pipeline
          optional: true
      image: python:3.9.10-slim
      volumeMounts:
      - mountPath: /kfp-launcher
        name: kfp-launcher
    initContainers:
    - command:
      - launcher
      - --copy
      - /kfp-launcher/launch
      image: gcr.io/ml-pipeline/kfp-launcher:1.8.7
      mirrorVolumeMounts: true
      name: kfp-launcher
    inputs:
      artifacts:
      - name: init-databag-dataset
        path: /tmp/inputs/dataframe/data
      parameters:
      - name: pipeline-name
      - name: pipeline-root
    metadata:
      annotations:
        pipelines.kubeflow.org/component_ref: '{"digest": "fe07c3ca72262e4184bfbe98fcebeb7de40547ee9eddc3007f06434c383d3b26",
          "url": "../../components/preprocess-data/component.yaml"}'
        pipelines.kubeflow.org/v2_component: 'true'
      labels:
        pipelines.kubeflow.org/enable_caching: 'true'
        pipelines.kubeflow.org/kfp_sdk_version: 1.8.12
        pipelines.kubeflow.org/pipeline-sdk-type: kfp
        pipelines.kubeflow.org/v2_component: 'true'
    name: preprocess-data
    outputs:
      artifacts:
      - name: preprocess-data-x
        path: /tmp/outputs/x/data
      - name: preprocess-data-y
        path: /tmp/outputs/y/data
    volumes:
    - name: kfp-launcher
  - dag:
      tasks:
      - arguments:
          artifacts:
          - from: '{{tasks.train-random-forest.outputs.artifacts.train-random-forest-metrics}}'
            name: train-random-forest-metrics
          parameters:
          - name: pipeline-name
            value: '{{inputs.parameters.pipeline-name}}'
          - name: pipeline-root
            value: '{{inputs.parameters.pipeline-root}}'
          - name: solution_name
            value: '{{inputs.parameters.solution_name}}'
        dependencies:
        - train-random-forest
        name: get-metrics
        template: get-metrics
      - arguments:
          parameters:
          - name: bucket
            value: '{{inputs.parameters.bucket}}'
          - name: file_name
            value: '{{inputs.parameters.file_name}}'
          - name: pipeline-name
            value: '{{inputs.parameters.pipeline-name}}'
          - name: pipeline-root
            value: '{{inputs.parameters.pipeline-root}}'
        name: init-databag
        template: init-databag
      - arguments:
          artifacts:
          - from: '{{tasks.init-databag.outputs.artifacts.init-databag-dataset}}'
            name: init-databag-dataset
          parameters:
          - name: pipeline-name
            value: '{{inputs.parameters.pipeline-name}}'
          - name: pipeline-root
            value: '{{inputs.parameters.pipeline-root}}'
        dependencies:
        - init-databag
        name: preprocess-data
        template: preprocess-data
      - arguments:
          artifacts:
          - from: '{{tasks.preprocess-data.outputs.artifacts.preprocess-data-x}}'
            name: preprocess-data-x
          - from: '{{tasks.preprocess-data.outputs.artifacts.preprocess-data-y}}'
            name: preprocess-data-y
          parameters:
          - name: pipeline-name
            value: '{{inputs.parameters.pipeline-name}}'
          - name: pipeline-root
            value: '{{inputs.parameters.pipeline-root}}'
        dependencies:
        - preprocess-data
        name: train-random-forest
        template: train-random-forest
      - arguments:
          parameters:
          - name: pipeline-name
            value: '{{inputs.parameters.pipeline-name}}'
          - name: pipeline-root
            value: '{{inputs.parameters.pipeline-root}}'
          - name: solution_name
            value: '{{inputs.parameters.solution_name}}'
        name: update-status
        template: update-status
      - arguments:
          artifacts:
          - from: '{{tasks.init-databag.outputs.artifacts.init-databag-dataset}}'
            name: init-databag-dataset
          parameters:
          - name: pipeline-name
            value: '{{inputs.parameters.pipeline-name}}'
          - name: pipeline-root
            value: '{{inputs.parameters.pipeline-root}}'
          - name: solution_name
            value: '{{inputs.parameters.solution_name}}'
        dependencies:
        - init-databag
        name: update-status-2
        template: update-status-2
      - arguments:
          artifacts:
          - from: '{{tasks.train-random-forest.outputs.artifacts.train-random-forest-metrics}}'
            name: train-random-forest-metrics
          parameters:
          - name: pipeline-name
            value: '{{inputs.parameters.pipeline-name}}'
          - name: pipeline-root
            value: '{{inputs.parameters.pipeline-root}}'
          - name: solution_name
            value: '{{inputs.parameters.solution_name}}'
        dependencies:
        - train-random-forest
        name: update-status-3
        template: update-status-3
    inputs:
      parameters:
      - name: bucket
      - name: file_name
      - name: pipeline-name
      - name: pipeline-root
      - name: solution_name
    name: titanic-randomforest-pipeline
  - container:
      args:
      - sh
      - -c
      - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3\
        \ -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
        \ python3 -m pip install --quiet     --no-warn-script-location 'pandas>=1.4.0'\
        \ 'scikit-learn>=1.0.2' 'kfp==1.8.12' && \"$0\" \"$@\"\n"
      - sh
      - -ec
      - 'program_path=$(mktemp -d)

        printf "%s" "$0" > "$program_path/ephemeral_component.py"

        python3 -m kfp.v2.components.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

        '
      - "\nimport kfp\nfrom kfp.v2 import dsl\nfrom kfp.v2.dsl import *\nfrom typing\
        \ import *\n\ndef train_random_forest(\n    data_x: Input[Dataset],\n    data_y:\
        \ Input[Dataset],\n    class_metrics: Output[ClassificationMetrics],\n   \
        \ metrics: Output[Metrics],\n) -> float:\n    import pandas as pd\n    from\
        \ sklearn.ensemble import RandomForestClassifier\n    from sklearn.metrics\
        \ import confusion_matrix\n    from sklearn.model_selection import train_test_split\n\
        \n    random_state = 42\n    with open(data_x.path, \"r\") as f:\n       \
        \ df_x = pd.read_csv(f)\n    with open(data_y.path, \"r\") as f:\n       \
        \ df_y = pd.read_csv(f)\n    x_train, x_test, y_train, y_test = train_test_split(\n\
        \        df_x, df_y, test_size=0.33, random_state=random_state\n    )\n  \
        \  clf = RandomForestClassifier(n_estimators=100, random_state=random_state)\n\
        \    clf.fit(x_train, y_train)\n    score = clf.score(x_test, y_test)\n  \
        \  y_pred = clf.predict(x_test)\n    conf_matrix = confusion_matrix(y_test,\
        \ y_pred).tolist()\n    class_metrics.log_confusion_matrix([\"Died\", \"Survived\"\
        ], conf_matrix)\n    metrics.log_metric(\"accuracy\", score)\n    return score\n\
        \n"
      - --executor_input
      - '{{$}}'
      - --function_to_execute
      - train_random_forest
      command:
      - /kfp-launcher/launch
      - --mlmd_server_address
      - $(METADATA_GRPC_SERVICE_HOST)
      - --mlmd_server_port
      - $(METADATA_GRPC_SERVICE_PORT)
      - --runtime_info_json
      - $(KFP_V2_RUNTIME_INFO)
      - --container_image
      - $(KFP_V2_IMAGE)
      - --task_name
      - train-random-forest
      - --pipeline_name
      - '{{inputs.parameters.pipeline-name}}'
      - --run_id
      - $(KFP_RUN_ID)
      - --run_resource
      - workflows.argoproj.io/$(WORKFLOW_ID)
      - --namespace
      - $(KFP_NAMESPACE)
      - --pod_name
      - $(KFP_POD_NAME)
      - --pod_uid
      - $(KFP_POD_UID)
      - --pipeline_root
      - '{{inputs.parameters.pipeline-root}}'
      - --enable_caching
      - $(ENABLE_CACHING)
      - --
      - --
      env:
      - name: KFP_POD_NAME
        valueFrom:
          fieldRef:
            fieldPath: metadata.name
      - name: KFP_POD_UID
        valueFrom:
          fieldRef:
            fieldPath: metadata.uid
      - name: KFP_NAMESPACE
        valueFrom:
          fieldRef:
            fieldPath: metadata.namespace
      - name: WORKFLOW_ID
        valueFrom:
          fieldRef:
            fieldPath: metadata.labels['workflows.argoproj.io/workflow']
      - name: KFP_RUN_ID
        valueFrom:
          fieldRef:
            fieldPath: metadata.labels['pipeline/runid']
      - name: ENABLE_CACHING
        valueFrom:
          fieldRef:
            fieldPath: metadata.labels['pipelines.kubeflow.org/enable_caching']
      - name: KFP_V2_IMAGE
        value: python:3.9.10-slim
      - name: KFP_V2_RUNTIME_INFO
        value: '{"inputParameters": {}, "inputArtifacts": {"data_x": {"metadataPath":
          "/tmp/inputs/data_x/data", "schemaTitle": "system.Dataset", "instanceSchema":
          "", "schemaVersion": "0.0.1"}, "data_y": {"metadataPath": "/tmp/inputs/data_y/data",
          "schemaTitle": "system.Dataset", "instanceSchema": "", "schemaVersion":
          "0.0.1"}}, "outputParameters": {"Output": {"type": "DOUBLE", "path": "/tmp/outputs/Output/data"}},
          "outputArtifacts": {"class_metrics": {"schemaTitle": "system.ClassificationMetrics",
          "instanceSchema": "", "schemaVersion": "0.0.1", "metadataPath": "/tmp/outputs/class_metrics/data"},
          "metrics": {"schemaTitle": "system.Metrics", "instanceSchema": "", "schemaVersion":
          "0.0.1", "metadataPath": "/tmp/outputs/metrics/data"}}}'
      envFrom:
      - configMapRef:
          name: metadata-grpc-configmap
          optional: true
      - configMapRef:
          name: os4ml-pipeline
          optional: true
      image: python:3.9.10-slim
      volumeMounts:
      - mountPath: /kfp-launcher
        name: kfp-launcher
    initContainers:
    - command:
      - launcher
      - --copy
      - /kfp-launcher/launch
      image: gcr.io/ml-pipeline/kfp-launcher:1.8.7
      mirrorVolumeMounts: true
      name: kfp-launcher
    inputs:
      artifacts:
      - name: preprocess-data-x
        path: /tmp/inputs/data_x/data
      - name: preprocess-data-y
        path: /tmp/inputs/data_y/data
      parameters:
      - name: pipeline-name
      - name: pipeline-root
    metadata:
      annotations:
        pipelines.kubeflow.org/component_ref: '{"digest": "057f2834076ed656a12a1f505356549d9cfb62f8178a0846320ad986f3dd4430",
          "url": "../../components/train-random-forest/component.yaml"}'
        pipelines.kubeflow.org/v2_component: 'true'
      labels:
        pipelines.kubeflow.org/enable_caching: 'true'
        pipelines.kubeflow.org/kfp_sdk_version: 1.8.12
        pipelines.kubeflow.org/pipeline-sdk-type: kfp
        pipelines.kubeflow.org/v2_component: 'true'
    name: train-random-forest
    outputs:
      artifacts:
      - name: train-random-forest-Output
        path: /tmp/outputs/Output/data
      - name: train-random-forest-class_metrics
        path: /tmp/outputs/class_metrics/data
      - name: train-random-forest-metrics
        path: /tmp/outputs/metrics/data
    volumes:
    - name: kfp-launcher
  - container:
      args:
      - sh
      - -c
      - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3\
        \ -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
        \ python3 -m pip install --quiet     --no-warn-script-location 'kfp==1.8.12'\
        \ && \"$0\" \"$@\"\n"
      - sh
      - -ec
      - 'program_path=$(mktemp -d)

        printf "%s" "$0" > "$program_path/ephemeral_component.py"

        python3 -m kfp.v2.components.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

        '
      - "\nimport kfp\nfrom kfp.v2 import dsl\nfrom kfp.v2.dsl import *\nfrom typing\
        \ import *\n\ndef update_status(\n    status: str = \"\", depends_on: Artifact\
        \ = None, solution_name: str = \"\"\n):\n    from src.components.update_status\
        \ import update_status\n\n    update_status(status, solution_name=solution_name)\n\
        \n"
      - --executor_input
      - '{{$}}'
      - --function_to_execute
      - update_status
      command:
      - /kfp-launcher/launch
      - --mlmd_server_address
      - $(METADATA_GRPC_SERVICE_HOST)
      - --mlmd_server_port
      - $(METADATA_GRPC_SERVICE_PORT)
      - --runtime_info_json
      - $(KFP_V2_RUNTIME_INFO)
      - --container_image
      - $(KFP_V2_IMAGE)
      - --task_name
      - update-status
      - --pipeline_name
      - '{{inputs.parameters.pipeline-name}}'
      - --run_id
      - $(KFP_RUN_ID)
      - --run_resource
      - workflows.argoproj.io/$(WORKFLOW_ID)
      - --namespace
      - $(KFP_NAMESPACE)
      - --pod_name
      - $(KFP_POD_NAME)
      - --pod_uid
      - $(KFP_POD_UID)
      - --pipeline_root
      - '{{inputs.parameters.pipeline-root}}'
      - --enable_caching
      - $(ENABLE_CACHING)
      - --
      - solution_name={{inputs.parameters.solution_name}}
      - status=Solution created
      - --
      env:
      - name: KFP_POD_NAME
        valueFrom:
          fieldRef:
            fieldPath: metadata.name
      - name: KFP_POD_UID
        valueFrom:
          fieldRef:
            fieldPath: metadata.uid
      - name: KFP_NAMESPACE
        valueFrom:
          fieldRef:
            fieldPath: metadata.namespace
      - name: WORKFLOW_ID
        valueFrom:
          fieldRef:
            fieldPath: metadata.labels['workflows.argoproj.io/workflow']
      - name: KFP_RUN_ID
        valueFrom:
          fieldRef:
            fieldPath: metadata.labels['pipeline/runid']
      - name: ENABLE_CACHING
        valueFrom:
          fieldRef:
            fieldPath: metadata.labels['pipelines.kubeflow.org/enable_caching']
      - name: KFP_V2_IMAGE
        value: gitlab-registry.wogra.com/developer/wogra/os4ml/python:latest
      - name: KFP_V2_RUNTIME_INFO
        value: '{"inputParameters": {"solution_name": {"type": "STRING"}, "status":
          {"type": "STRING"}}, "inputArtifacts": {}, "outputParameters": {}, "outputArtifacts":
          {}}'
      envFrom:
      - configMapRef:
          name: metadata-grpc-configmap
          optional: true
      - configMapRef:
          name: os4ml-pipeline
          optional: true
      image: gitlab-registry.wogra.com/developer/wogra/os4ml/python:latest
      volumeMounts:
      - mountPath: /kfp-launcher
        name: kfp-launcher
    initContainers:
    - command:
      - launcher
      - --copy
      - /kfp-launcher/launch
      image: gcr.io/ml-pipeline/kfp-launcher:1.8.7
      mirrorVolumeMounts: true
      name: kfp-launcher
    inputs:
      parameters:
      - name: pipeline-name
      - name: pipeline-root
      - name: solution_name
    metadata:
      annotations:
        pipelines.kubeflow.org/arguments.parameters: '{"solution_name": "{{inputs.parameters.solution_name}}",
          "status": "Solution created"}'
        pipelines.kubeflow.org/component_ref: '{"digest": "e4d6d92cfcbd5bdf4e7afb63c9c7a1318f6b95a4549a04b72a8b5d604905b331",
          "url": "../../components/update-status/component.yaml"}'
        pipelines.kubeflow.org/v2_component: 'true'
      labels:
        pipelines.kubeflow.org/enable_caching: 'true'
        pipelines.kubeflow.org/kfp_sdk_version: 1.8.12
        pipelines.kubeflow.org/pipeline-sdk-type: kfp
        pipelines.kubeflow.org/v2_component: 'true'
    name: update-status
    volumes:
    - name: kfp-launcher
  - container:
      args:
      - sh
      - -c
      - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3\
        \ -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
        \ python3 -m pip install --quiet     --no-warn-script-location 'kfp==1.8.12'\
        \ && \"$0\" \"$@\"\n"
      - sh
      - -ec
      - 'program_path=$(mktemp -d)

        printf "%s" "$0" > "$program_path/ephemeral_component.py"

        python3 -m kfp.v2.components.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

        '
      - "\nimport kfp\nfrom kfp.v2 import dsl\nfrom kfp.v2.dsl import *\nfrom typing\
        \ import *\n\ndef update_status(\n    status: str = \"\", depends_on: Artifact\
        \ = None, solution_name: str = \"\"\n):\n    from src.components.update_status\
        \ import update_status\n\n    update_status(status, solution_name=solution_name)\n\
        \n"
      - --executor_input
      - '{{$}}'
      - --function_to_execute
      - update_status
      command:
      - /kfp-launcher/launch
      - --mlmd_server_address
      - $(METADATA_GRPC_SERVICE_HOST)
      - --mlmd_server_port
      - $(METADATA_GRPC_SERVICE_PORT)
      - --runtime_info_json
      - $(KFP_V2_RUNTIME_INFO)
      - --container_image
      - $(KFP_V2_IMAGE)
      - --task_name
      - update-status-2
      - --pipeline_name
      - '{{inputs.parameters.pipeline-name}}'
      - --run_id
      - $(KFP_RUN_ID)
      - --run_resource
      - workflows.argoproj.io/$(WORKFLOW_ID)
      - --namespace
      - $(KFP_NAMESPACE)
      - --pod_name
      - $(KFP_POD_NAME)
      - --pod_uid
      - $(KFP_POD_UID)
      - --pipeline_root
      - '{{inputs.parameters.pipeline-root}}'
      - --enable_caching
      - $(ENABLE_CACHING)
      - --
      - solution_name={{inputs.parameters.solution_name}}
      - status=Solver running
      - --
      env:
      - name: KFP_POD_NAME
        valueFrom:
          fieldRef:
            fieldPath: metadata.name
      - name: KFP_POD_UID
        valueFrom:
          fieldRef:
            fieldPath: metadata.uid
      - name: KFP_NAMESPACE
        valueFrom:
          fieldRef:
            fieldPath: metadata.namespace
      - name: WORKFLOW_ID
        valueFrom:
          fieldRef:
            fieldPath: metadata.labels['workflows.argoproj.io/workflow']
      - name: KFP_RUN_ID
        valueFrom:
          fieldRef:
            fieldPath: metadata.labels['pipeline/runid']
      - name: ENABLE_CACHING
        valueFrom:
          fieldRef:
            fieldPath: metadata.labels['pipelines.kubeflow.org/enable_caching']
      - name: KFP_V2_IMAGE
        value: gitlab-registry.wogra.com/developer/wogra/os4ml/python:latest
      - name: KFP_V2_RUNTIME_INFO
        value: '{"inputParameters": {"solution_name": {"type": "STRING"}, "status":
          {"type": "STRING"}}, "inputArtifacts": {"depends_on": {"metadataPath": "/tmp/inputs/depends_on/data",
          "schemaTitle": "system.Artifact", "instanceSchema": "", "schemaVersion":
          "0.0.1"}}, "outputParameters": {}, "outputArtifacts": {}}'
      envFrom:
      - configMapRef:
          name: metadata-grpc-configmap
          optional: true
      - configMapRef:
          name: os4ml-pipeline
          optional: true
      image: gitlab-registry.wogra.com/developer/wogra/os4ml/python:latest
      volumeMounts:
      - mountPath: /kfp-launcher
        name: kfp-launcher
    initContainers:
    - command:
      - launcher
      - --copy
      - /kfp-launcher/launch
      image: gcr.io/ml-pipeline/kfp-launcher:1.8.7
      mirrorVolumeMounts: true
      name: kfp-launcher
    inputs:
      artifacts:
      - name: init-databag-dataset
        path: /tmp/inputs/depends_on/data
      parameters:
      - name: pipeline-name
      - name: pipeline-root
      - name: solution_name
    metadata:
      annotations:
        pipelines.kubeflow.org/arguments.parameters: '{"solution_name": "{{inputs.parameters.solution_name}}",
          "status": "Solver running"}'
        pipelines.kubeflow.org/component_ref: '{"digest": "e4d6d92cfcbd5bdf4e7afb63c9c7a1318f6b95a4549a04b72a8b5d604905b331",
          "url": "../../components/update-status/component.yaml"}'
        pipelines.kubeflow.org/v2_component: 'true'
      labels:
        pipelines.kubeflow.org/enable_caching: 'true'
        pipelines.kubeflow.org/kfp_sdk_version: 1.8.12
        pipelines.kubeflow.org/pipeline-sdk-type: kfp
        pipelines.kubeflow.org/v2_component: 'true'
    name: update-status-2
    volumes:
    - name: kfp-launcher
  - container:
      args:
      - sh
      - -c
      - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3\
        \ -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
        \ python3 -m pip install --quiet     --no-warn-script-location 'kfp==1.8.12'\
        \ && \"$0\" \"$@\"\n"
      - sh
      - -ec
      - 'program_path=$(mktemp -d)

        printf "%s" "$0" > "$program_path/ephemeral_component.py"

        python3 -m kfp.v2.components.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

        '
      - "\nimport kfp\nfrom kfp.v2 import dsl\nfrom kfp.v2.dsl import *\nfrom typing\
        \ import *\n\ndef update_status(\n    status: str = \"\", depends_on: Artifact\
        \ = None, solution_name: str = \"\"\n):\n    from src.components.update_status\
        \ import update_status\n\n    update_status(status, solution_name=solution_name)\n\
        \n"
      - --executor_input
      - '{{$}}'
      - --function_to_execute
      - update_status
      command:
      - /kfp-launcher/launch
      - --mlmd_server_address
      - $(METADATA_GRPC_SERVICE_HOST)
      - --mlmd_server_port
      - $(METADATA_GRPC_SERVICE_PORT)
      - --runtime_info_json
      - $(KFP_V2_RUNTIME_INFO)
      - --container_image
      - $(KFP_V2_IMAGE)
      - --task_name
      - update-status-3
      - --pipeline_name
      - '{{inputs.parameters.pipeline-name}}'
      - --run_id
      - $(KFP_RUN_ID)
      - --run_resource
      - workflows.argoproj.io/$(WORKFLOW_ID)
      - --namespace
      - $(KFP_NAMESPACE)
      - --pod_name
      - $(KFP_POD_NAME)
      - --pod_uid
      - $(KFP_POD_UID)
      - --pipeline_root
      - '{{inputs.parameters.pipeline-root}}'
      - --enable_caching
      - $(ENABLE_CACHING)
      - --
      - solution_name={{inputs.parameters.solution_name}}
      - status=Solver finished
      - --
      env:
      - name: KFP_POD_NAME
        valueFrom:
          fieldRef:
            fieldPath: metadata.name
      - name: KFP_POD_UID
        valueFrom:
          fieldRef:
            fieldPath: metadata.uid
      - name: KFP_NAMESPACE
        valueFrom:
          fieldRef:
            fieldPath: metadata.namespace
      - name: WORKFLOW_ID
        valueFrom:
          fieldRef:
            fieldPath: metadata.labels['workflows.argoproj.io/workflow']
      - name: KFP_RUN_ID
        valueFrom:
          fieldRef:
            fieldPath: metadata.labels['pipeline/runid']
      - name: ENABLE_CACHING
        valueFrom:
          fieldRef:
            fieldPath: metadata.labels['pipelines.kubeflow.org/enable_caching']
      - name: KFP_V2_IMAGE
        value: gitlab-registry.wogra.com/developer/wogra/os4ml/python:latest
      - name: KFP_V2_RUNTIME_INFO
        value: '{"inputParameters": {"solution_name": {"type": "STRING"}, "status":
          {"type": "STRING"}}, "inputArtifacts": {"depends_on": {"metadataPath": "/tmp/inputs/depends_on/data",
          "schemaTitle": "system.Artifact", "instanceSchema": "", "schemaVersion":
          "0.0.1"}}, "outputParameters": {}, "outputArtifacts": {}}'
      envFrom:
      - configMapRef:
          name: metadata-grpc-configmap
          optional: true
      - configMapRef:
          name: os4ml-pipeline
          optional: true
      image: gitlab-registry.wogra.com/developer/wogra/os4ml/python:latest
      volumeMounts:
      - mountPath: /kfp-launcher
        name: kfp-launcher
    initContainers:
    - command:
      - launcher
      - --copy
      - /kfp-launcher/launch
      image: gcr.io/ml-pipeline/kfp-launcher:1.8.7
      mirrorVolumeMounts: true
      name: kfp-launcher
    inputs:
      artifacts:
      - name: train-random-forest-metrics
        path: /tmp/inputs/depends_on/data
      parameters:
      - name: pipeline-name
      - name: pipeline-root
      - name: solution_name
    metadata:
      annotations:
        pipelines.kubeflow.org/arguments.parameters: '{"solution_name": "{{inputs.parameters.solution_name}}",
          "status": "Solver finished"}'
        pipelines.kubeflow.org/component_ref: '{"digest": "e4d6d92cfcbd5bdf4e7afb63c9c7a1318f6b95a4549a04b72a8b5d604905b331",
          "url": "../../components/update-status/component.yaml"}'
        pipelines.kubeflow.org/v2_component: 'true'
      labels:
        pipelines.kubeflow.org/enable_caching: 'true'
        pipelines.kubeflow.org/kfp_sdk_version: 1.8.12
        pipelines.kubeflow.org/pipeline-sdk-type: kfp
        pipelines.kubeflow.org/v2_component: 'true'
    name: update-status-3
    volumes:
    - name: kfp-launcher
